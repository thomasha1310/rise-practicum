{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: E‑commerce Delivery Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An online retailer promises 3‑day shipping. Occasionally, storms delay a few packages. Can you confidently continue advertising that you offer “3 day delivery” given occasional storm delays? To do this, you need to complete three tasks. \n",
    "\n",
    "1) run the below cell to simulate the data\n",
    "\n",
    "2) calculate a log-likelihood estimate where we assume delivery times $~ N(\\mu, \\sigma^2)$ with known $\\sigma = 0.5$ Find the $\\mu$ that maximizes the likelihood of $\\mu$ (note we will be minimizing the log of the likelihood.)\n",
    "\n",
    "3) Calculate a 95% boostrap CI: Resample the 100 observations 2000 times, compute $\\hat{\\mu}$ for each bootstrap sample, and take the 2.5 % and 97.5 % percentiles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(123)\n",
    "# 100 on‑time deliveries ~ N(3 days, 0.5**2)\n",
    "delivery_times = np.random.normal(3.0, 0.5, size=100)\n",
    "# 3 extreme delays\n",
    "delivery_times[:3] += np.array([5.0, 7.0, 4.0])\n",
    "\n",
    "plt.hist(delivery_times)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# 1. Define neg‐log‐likelihood correctly \n",
    "def neg_log_lik(mu, data):\n",
    "    return -np.sum(stats.norm.logpdf(data, loc=mu, scale=0.5))\n",
    "\n",
    "# 2. Define your grid\n",
    "mu_values = np.linspace(0.0, 6.0, 601)\n",
    "\n",
    "# 3. Compute NLL on full data\n",
    "nlls = [ neg_log_lik(mu, delivery_times) for mu in mu_values ]\n",
    "\n",
    "# your task: find the best value from nlls\n",
    "best_mu = mu_values[np.argmin(nlls)]\n",
    "print(\"Best mu (MLE):\", best_mu)\n",
    "\n",
    "# 4. Bootstrap\n",
    "boots = []\n",
    "for _ in range(2000):\n",
    "    sample = np.random.choice(delivery_times, size=100, replace=True)\n",
    "    nlls_bs = [\n",
    "        -np.sum(stats.norm.logpdf(sample, loc=mu, scale=0.5))\n",
    "        for mu in mu_values\n",
    "    ]\n",
    "    boots.append(mu_values[np.argmin(nlls_bs)])\n",
    "\n",
    "# your task: get the 2.5 and 97.5 %ile from boots\n",
    "ci_lower = np.percentile(boots, 2.5)\n",
    "ci_upper = np.percentile(boots, 97.5)\n",
    "print(\"95% CI for mu from bootstrap:\", (ci_lower, ci_upper))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) What is $\\hat{\\mu}$? How far is it from 3.0 days, and how did the 3 outliers pull it?\n",
    "\n",
    "2) Does the 95 % CI include 3.0? What does that imply for your “3‑day promise”?\n",
    "\n",
    "3) If you removed the 3 delays, how would μ̂ and the CI change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $\\hat{\\mu} = 3.17$, which is slightly more than 3.0 days. The 3 outliers pulled the mean up slightly.\n",
    "2. The 95% CI includes 3.0, which implies that the 3-day promise is relatively accurate.\n",
    "3. If the three delays were removed, $\\hat{\\mu}$ would decrease and the size of the CI would decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Call‑Center Inter‑arrival Times\n",
    "\n",
    "A support center sees calls arriving with mean gap 5 min. Downtime causes a few very long gaps. Do you currently have enough call agents to keep the average hold‑times below 5 min? To do this you need to complete three tasks:\n",
    "\n",
    "1) run the below cell to simulate the data\n",
    "\n",
    "2) calculate a log-likelihood estimate where we assume call gaps $~ Exp(\\lambda)$. Find the $\\lambda$ that maximizes the likelihood of $\\lambda$ (note we will be minimizing the log of the likelihood.)\n",
    "\n",
    "3) Calculate a 95% boostrap CI: Resample the 200 observations 2000 times, compute $\\hat{\\lambda}$ for each bootstrap sample, and take the 2.5 % and 97.5 % percentiles.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudocode to help \n",
    "\n",
    "# 1. MLE (PAUSE HERE WHAT IS THIS FUNCTION DOING BELOW)\n",
    "\n",
    "# Reconstruct the data\n",
    "np.random.seed(42)\n",
    "gaps = np.random.exponential(scale=5.0, size=200)\n",
    "gaps[:5] += np.array([30, 45, 60, 25, 50])\n",
    "# plt.hist(gaps, bins=100)\n",
    "\n",
    "# 1. MLE for λ\n",
    "def neg_log_lik(λ, data):\n",
    "    return -np.sum(stats.expon.logpdf(data, scale=1/λ))\n",
    "\n",
    "# your task: create a grid of values to \"check\" (i.e., linspace like the last problem). Then, find the the best value from nlls\n",
    "λ_values = np.linspace(0.001, 2 * gaps.mean(), 601)\n",
    "nlls = [ neg_log_lik(λ, gaps) for λ in λ_values ]\n",
    "best_λ = λ_values[np.argmin(nlls)]\n",
    "print(\"Best λ:\", best_λ)\n",
    "\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "# 2. Bootstrap CI\n",
    "boots = []\n",
    "for _ in range(2000):\n",
    "    samp = np.random.choice(gaps, size=200, replace=True)\n",
    "    r = optimize.minimize(lambda l: neg_log_lik(l, samp), x0=0.2, bounds=[(1e-6, None)])\n",
    "    boots.append(r.x[0])\n",
    "\n",
    "# your task: get the 2.5 and 97.5 %ile from boots\n",
    "ci_lower = np.percentile(boots, 2.5)\n",
    "ci_upper = np.percentile(boots, 97.5)\n",
    "print(\"95% CI for λ:\", (ci_lower, ci_upper))\n",
    "\n",
    "print(\"mean:\", 1/best_λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) What is the estimated rate $\\hat{\\lambda}$? How does it compare to the true 0.2?\n",
    "\n",
    "2) How robust is $\\hat{\\lambda}$ to the 5 downtimes (i.e., do the 5 downtimes shift the mean at all)?\n",
    "\n",
    "3) Does the CI cover 0.2? What does this mean for staffing predictions?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The estimated $\\hat{\\lambda}$ is approximately 0.174, which is slightly less than 0.2.\n",
    "2. Without the 5 downtimes, the mean is roughly 4.86. Including the downtimes, the mean is 5.74, so $\\hat\\lambda$ is not particularly robust to downtimes.\n",
    "3. The CI covers 0.2, so staffing is generally enough except for rare downtimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Household Electricity Usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hourly household consumption (kWh) is log‑normally distributed (median ~ 20 kWh); rare equipment failures spike usage. Find the most value for the electricity usage and then construct a confidence interval for them. You've only budgeted to use 20 kWh per hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "np.random.seed(7)\n",
    "usage = np.random.lognormal(mean=np.log(20), sigma=0.3, size=150)\n",
    "usage[:4] *= np.array([5, 4, 6, 3])\n",
    "\n",
    "# plt.hist(usage)\n",
    "\n",
    "def neg_log_lik(mu, data):\n",
    "    return -np.sum(stats.lognorm.logpdf(data, s=0.3, scale=np.exp(mu)))\n",
    "\n",
    "mu_values = np.linspace(2.0, 4.0, 401)\n",
    "nlls = [ neg_log_lik(mu, usage) for mu in mu_values ]\n",
    "best_mu = mu_values[np.argmin(nlls)]\n",
    "print(\"Best mu:\", best_mu)\n",
    "print(\"Mean:\", np.exp(best_mu + (0.3 ** 2) / 2))\n",
    "print(\"Median:\", np.exp(best_mu))\n",
    "\n",
    "# 2. Bootstrap CI\n",
    "boots = []\n",
    "for _ in range(2000):\n",
    "    samp = np.random.choice(usage, size=150, replace=True)\n",
    "    nlls_bs = [ neg_log_lik(mu, samp) for mu in mu_values ]\n",
    "    boots.append(mu_values[np.argmin(nlls_bs)])\n",
    "\n",
    "# your task: get the 2.5 and 97.5 %ile from boots\n",
    "ci_lower = np.percentile(boots, 2.5)\n",
    "ci_upper = np.percentile(boots, 97.5)\n",
    "print(\"95% CI for mu:\", (ci_lower, ci_upper))\n",
    "print(\"Lower mean:\", np.exp(ci_lower + (0.3 ** 2) / 2))\n",
    "print(\"Upper mean:\", np.exp(ci_upper + (0.3 ** 2) / 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) What is the estimated median usage?\n",
    "\n",
    "2) Would you budget 20 kWh per hour per home confidently or should you budget more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The median usage is approximately 20.49 kWh.\n",
    "2. It is probably better to budget slightly more than 20 kWh per hour per home."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
